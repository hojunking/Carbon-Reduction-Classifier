{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FuDpa-TyFJlY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'inception_resnet_v2',\n",
    "    'img_size': 260,\n",
    "    'epochs': 200,\n",
    "    'train_bs':128,\n",
    "    'valid_bs':32,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'num_workers': 8,\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "b9t1W6f6FJlZ"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore') \n",
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "\n",
    "def seed_everything(seed: int=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "                        cm, classes, runid, epoch, \n",
    "                        f1, normalize=False, \n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(f'{title}-{runid}-{epoch}-{f1:.4f}')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(f'./cms/cm-{runid}.jpg', dpi=400)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvgOAyS9FJla"
   },
   "source": [
    "### 학습 전 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnxc4zUEFJlb"
   },
   "source": [
    "- 테스트 데이터셋은 대표적인 화가 50명에 대한 예술 작품(이미지)의 일부분(약 1/4)만 제공 --> RandomResizedCrop으로 원본의 24%~26%를 자른 후 Noisy Student B7 모델에 맞게 600 x 600으로 resize\n",
    "- 여러 augmentation들과 TTA를 시도해봤지만 public 점수에 악영향을 줘서 HorizontalFlip 하나만 p=0.5로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jw1FLptKFJlb"
   },
   "outputs": [],
   "source": [
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.RandomResizedCrop(\n",
    "            height=600, \n",
    "            width=600, \n",
    "            scale=(0.24, 0.26),\n",
    "            ratio=(0.90, 1.10),\n",
    "            always_apply=True\n",
    "            ),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "        A.Resize(600, 600),\n",
    "        A.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBjBmEVAFJlc"
   },
   "source": [
    "- custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yh9Aeir_FJlc"
   },
   "outputs": [],
   "source": [
    "class ARTDataset(Dataset):\n",
    "    def __init__(self, phase, root, csv, transform) -> None:\n",
    "        super().__init__()\n",
    "        df = csv.sort_values(by=['id'])\n",
    "        self.phase = phase\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.images = df['img_path']\n",
    "\n",
    "        if self.phase != 'test':\n",
    "            self.label = df['artist']\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images.iloc[index]\n",
    "        if self.phase != 'test':\n",
    "            label = int(self.label.iloc[index])\n",
    "\n",
    "        image_path = f'{self.root}/{image_path[2:]}'\n",
    "        temp = Image.open(image_path).convert(\"RGB\")\n",
    "        image = np.array(temp).copy()\n",
    "        temp.close()\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "\n",
    "        if self.phase != 'test':\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDq8xXAXFJlc"
   },
   "source": [
    "- 10 epoch동안 F1 score가 갱신되지 않으면 조기 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Qe3cALtrFJld"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uALHnqfNFJld"
   },
   "source": [
    "- **trainset**을 불러와 LabelEncoder에 fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rtrBqOczFJld"
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('../Data/data/train.csv')\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "train_csv['artist'] = le.fit_transform(train_csv['artist'].values)\n",
    "\n",
    "assert len(le.classes_) == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bW5g_wxDFJld"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRkPguBVFJld"
   },
   "source": [
    "- 일반 KFold를 사용하면 가끔 특정 클래스가 포함되지 않은 폴드가 생겨 StratifiedKFold를 사용\n",
    "- Fold마다 훈련 세트와 검증 세트를 나누고, trainset의 class 별 이미지 수에 반비례하는 weight를 설정 \n",
    "- 클래스 별 가중치를 구하고, 학습 세트 속 이미지에 weight를 대응시키기 위해 shuffle은 False가 되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0BcU95DFJle"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_cnts: 50\n",
      "num_samples:5319\n",
      "{'Jackson Pollock': 279.95, 'Eugene Delacroix': 221.62, 'Andrei Rublev': 80.59, 'Peter Paul Rubens': 61.14, 'Mikhail Vrubel': 50.18, 'El Greco': 90.15, 'Claude Monet': 100.36, 'Pieter Bruegel': 69.99, 'Pierre-Auguste Renoir': 25.33, 'Andy Warhol': 44.7, 'Marc Chagall': 34.1, 'Georges Seurat': 197.0, 'Henri Rousseau': 113.17, 'Kazimir Malevich': 64.87, 'Paul Klee': 41.55, 'Jan van Eyck': 93.32, 'Rembrandt': 32.63, 'Leonardo da Vinci': 58.45, 'Albrecht Du rer': 26.86, 'Pablo Picasso': 19.56, 'Alfred Sisley': 36.18, 'Vincent van Gogh': 9.38, 'Frida Kahlo': 69.99, 'Michelangelo': 171.58, 'Edgar Degas': 12.06, 'Diego Velazquez': 73.88, 'Raphael': 80.59, 'Paul Gauguin': 26.86, 'Edvard Munch': 132.97, 'Joan Miro': 78.22, 'Vasiliy Kandinskiy': 98.5, 'Edouard Manet': 94.98, 'Gustave Courbet': 139.97, 'Diego Rivera': 118.2, 'Amedeo Modigliani': 44.7, 'Titian': 34.1, 'Hieronymus Bosch': 51.64, 'Rene Magritte': 43.24, 'Camille Pissarro': 93.32, 'Sandro Botticelli': 49.25, 'Salvador Dali': 59.76, 'Caravaggio': 183.41, 'Francisco Goya': 28.91, 'Gustav Klimt': 85.79, 'William Turner': 136.38, 'Henri de Toulouse-Lautrec': 96.71, 'Piet Mondrian': 100.36, 'Giotto di Bondone': 81.83, 'Henri Matisse': 48.8, 'Paul Cezanne': 183.41}\n"
     ]
=======
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
>>>>>>> 7ed536d2ac0b9bb828f737e173a0826051630394
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hojunking/carbon_reduction_project/blob/main/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "jLFeeh2OMjuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XlpaIBbNxzK-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "yWMosx9B7Xmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47628c9-a22b-49e0-dac3-6ee3bde4b0a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I-aMGPg8NloO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Setting"
      ],
      "metadata": {
        "id": "HTlY-5isNofS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    'IMG_SIZE':224,\n",
        "    'EPOCHS':10,\n",
        "    'LEARNING_RATE':3e-4,\n",
        "    'BATCH_SIZE':64,\n",
        "    'SEED':41\n",
        "}"
      ],
      "metadata": {
        "id": "5FUHF-L8Nmuy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixed RandomSeed"
      ],
      "metadata": {
        "id": "NFWbevuUNsd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ],
      "metadata": {
        "id": "rQyx4TGcNuNM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-processing"
      ],
      "metadata": {
        "id": "BXexshs9N0Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRpHj77SN4wZ",
        "outputId": "cf3a18c3-480c-4514-8f79-a26d734353c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = \"/content/drive/MyDrive/탄소저감프로젝트/data\"\n",
        "\n",
        "img_names = []\n",
        "img_labels = []\n",
        "for folder, subfolders, filenames in os.walk(dir_path):\n",
        "    for img in filenames:\n",
        "        img_names.append(folder+'/'+img)\n",
        "        img_labels.append(img)\n",
        "\n",
        "print('Images: ',len(img_names))\n",
        "print(\"Image_labels:\", len(img_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK7j6CXJN-L0",
        "outputId": "aa53eff8-1a96-44dd-8507-f2955d604949"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images:  4067\n",
            "Image_labels: 4067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_labels"
      ],
      "metadata": {
        "id": "AB_B_k0_ThXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_df = pd.DataFrame(img_names, columns=['image_id'])\n",
        "trn_df['dir'] = trn_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
        "trn_df['image_id'] = trn_df['image_id'].apply(lambda x: os.path.basename(x))\n",
        "trn_df['label'] = img_labels\n",
        "train = trn_df\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dQzo41lgS-ud",
        "outputId": "61add907-2554-4620-83b1-53d1c23f39f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  image_id                                                dir  \\\n",
              "0     건물 계단_422.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "1     건물 계단_424.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "2     건물 계단_425.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "3     건물 계단_426.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "4     건물 계단_427.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "...                    ...                                                ...   \n",
              "4062   만보인증_222.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "4063   만보인증_227.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "4064   만보인증_224.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "4065   만보인증_225.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "4066   만보인증_226.jpg  /content/drive/MyDrive/탄소저감프로젝트/dat...   \n",
              "\n",
              "                     label  \n",
              "0     건물 계단_422.jpg  \n",
              "1     건물 계단_424.jpg  \n",
              "2     건물 계단_425.jpg  \n",
              "3     건물 계단_426.jpg  \n",
              "4     건물 계단_427.jpg  \n",
              "...                    ...  \n",
              "4062   만보인증_222.jpg  \n",
              "4063   만보인증_227.jpg  \n",
              "4064   만보인증_224.jpg  \n",
              "4065   만보인증_225.jpg  \n",
              "4066   만보인증_226.jpg  \n",
              "\n",
              "[4067 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc817f8a-768b-47f8-895c-ea40561b07d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>dir</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>건물 계단_422.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>건물 계단_422.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>건물 계단_424.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>건물 계단_424.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>건물 계단_425.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>건물 계단_425.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>건물 계단_426.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>건물 계단_426.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>건물 계단_427.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>건물 계단_427.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4062</th>\n",
              "      <td>만보인증_222.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>만보인증_222.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4063</th>\n",
              "      <td>만보인증_227.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>만보인증_227.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4064</th>\n",
              "      <td>만보인증_224.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>만보인증_224.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4065</th>\n",
              "      <td>만보인증_225.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>만보인증_225.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4066</th>\n",
              "      <td>만보인증_226.jpg</td>\n",
              "      <td>/content/drive/MyDrive/탄소저감프로젝트/dat...</td>\n",
              "      <td>만보인증_226.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4067 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc817f8a-768b-47f8-895c-ea40561b07d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc817f8a-768b-47f8-895c-ea40561b07d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc817f8a-768b-47f8-895c-ea40561b07d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding\n",
        "le = preprocessing.LabelEncoder()\n",
        "train['artist'] = le.fit_transform(train['artist'].values)"
      ],
      "metadata": {
        "id": "y8coAnRaOe4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAMf0OiAS5jz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}