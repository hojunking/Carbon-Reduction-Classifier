{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FuDpa-TyFJlY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'inception_resnet_v2',\n",
    "    'img_size': 260,\n",
    "    'epochs': 200,\n",
    "    'train_bs':128,\n",
    "    'valid_bs':32,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'num_workers': 8,\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "b9t1W6f6FJlZ"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore') \n",
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "\n",
    "def seed_everything(seed: int=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "                        cm, classes, runid, epoch, \n",
    "                        f1, normalize=False, \n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(f'{title}-{runid}-{epoch}-{f1:.4f}')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(f'./cms/cm-{runid}.jpg', dpi=400)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvgOAyS9FJla"
   },
   "source": [
    "### 학습 전 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnxc4zUEFJlb"
   },
   "source": [
    "- 테스트 데이터셋은 대표적인 화가 50명에 대한 예술 작품(이미지)의 일부분(약 1/4)만 제공 --> RandomResizedCrop으로 원본의 24%~26%를 자른 후 Noisy Student B7 모델에 맞게 600 x 600으로 resize\n",
    "- 여러 augmentation들과 TTA를 시도해봤지만 public 점수에 악영향을 줘서 HorizontalFlip 하나만 p=0.5로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jw1FLptKFJlb"
   },
   "outputs": [],
   "source": [
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.RandomResizedCrop(\n",
    "            height=600, \n",
    "            width=600, \n",
    "            scale=(0.24, 0.26),\n",
    "            ratio=(0.90, 1.10),\n",
    "            always_apply=True\n",
    "            ),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "        A.Resize(600, 600),\n",
    "        A.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBjBmEVAFJlc"
   },
   "source": [
    "- custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yh9Aeir_FJlc"
   },
   "outputs": [],
   "source": [
    "class ARTDataset(Dataset):\n",
    "    def __init__(self, phase, root, csv, transform) -> None:\n",
    "        super().__init__()\n",
    "        df = csv.sort_values(by=['id'])\n",
    "        self.phase = phase\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.images = df['img_path']\n",
    "\n",
    "        if self.phase != 'test':\n",
    "            self.label = df['artist']\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images.iloc[index]\n",
    "        if self.phase != 'test':\n",
    "            label = int(self.label.iloc[index])\n",
    "\n",
    "        image_path = f'{self.root}/{image_path[2:]}'\n",
    "        temp = Image.open(image_path).convert(\"RGB\")\n",
    "        image = np.array(temp).copy()\n",
    "        temp.close()\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "\n",
    "        if self.phase != 'test':\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDq8xXAXFJlc"
   },
   "source": [
    "- 10 epoch동안 F1 score가 갱신되지 않으면 조기 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Qe3cALtrFJld"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uALHnqfNFJld"
   },
   "source": [
    "- **trainset**을 불러와 LabelEncoder에 fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rtrBqOczFJld"
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('../Data/data/train.csv')\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "train_csv['artist'] = le.fit_transform(train_csv['artist'].values)\n",
    "\n",
    "assert len(le.classes_) == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bW5g_wxDFJld"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRkPguBVFJld"
   },
   "source": [
    "- 일반 KFold를 사용하면 가끔 특정 클래스가 포함되지 않은 폴드가 생겨 StratifiedKFold를 사용\n",
    "- Fold마다 훈련 세트와 검증 세트를 나누고, trainset의 class 별 이미지 수에 반비례하는 weight를 설정 \n",
    "- 클래스 별 가중치를 구하고, 학습 세트 속 이미지에 weight를 대응시키기 위해 shuffle은 False가 되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0BcU95DFJle"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_cnts: 50\n",
      "num_samples:5319\n",
      "{'Jackson Pollock': 279.95, 'Eugene Delacroix': 221.62, 'Andrei Rublev': 80.59, 'Peter Paul Rubens': 61.14, 'Mikhail Vrubel': 50.18, 'El Greco': 90.15, 'Claude Monet': 100.36, 'Pieter Bruegel': 69.99, 'Pierre-Auguste Renoir': 25.33, 'Andy Warhol': 44.7, 'Marc Chagall': 34.1, 'Georges Seurat': 197.0, 'Henri Rousseau': 113.17, 'Kazimir Malevich': 64.87, 'Paul Klee': 41.55, 'Jan van Eyck': 93.32, 'Rembrandt': 32.63, 'Leonardo da Vinci': 58.45, 'Albrecht Du rer': 26.86, 'Pablo Picasso': 19.56, 'Alfred Sisley': 36.18, 'Vincent van Gogh': 9.38, 'Frida Kahlo': 69.99, 'Michelangelo': 171.58, 'Edgar Degas': 12.06, 'Diego Velazquez': 73.88, 'Raphael': 80.59, 'Paul Gauguin': 26.86, 'Edvard Munch': 132.97, 'Joan Miro': 78.22, 'Vasiliy Kandinskiy': 98.5, 'Edouard Manet': 94.98, 'Gustave Courbet': 139.97, 'Diego Rivera': 118.2, 'Amedeo Modigliani': 44.7, 'Titian': 34.1, 'Hieronymus Bosch': 51.64, 'Rene Magritte': 43.24, 'Camille Pissarro': 93.32, 'Sandro Botticelli': 49.25, 'Salvador Dali': 59.76, 'Caravaggio': 183.41, 'Francisco Goya': 28.91, 'Gustav Klimt': 85.79, 'William Turner': 136.38, 'Henri de Toulouse-Lautrec': 96.71, 'Piet Mondrian': 100.36, 'Giotto di Bondone': 81.83, 'Henri Matisse': 48.8, 'Paul Cezanne': 183.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhojunking\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hojun/git/noisy_student_b7/wandb/run-20221124_183540-2ye10vph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hojunking/temp_test/runs/2ye10vph\" target=\"_blank\">20221124183531_fold0</a></strong> to <a href=\"https://wandb.ai/hojunking/temp_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Fold: 0\n",
      "Epoch 0/299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8695da3cd1d54687bbff619394290482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Loss: 3.7319 Macro F1: 0.0569\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a8d79e7cf14c4799c1b765aeb2214f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] Loss: 3.5571 Macro F1: 0.0652\n",
      "--------------------------------------------------\n",
      "Fold: 0\n",
      "Epoch 1/299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300d2177e8ac4e1d971079422cd6fb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Loss: 3.4305 Macro F1: 0.0994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a4d330f2834f2ab261b9ad3c505e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] Loss: 4.0162 Macro F1: 0.0826\n",
      "--------------------------------------------------\n",
      "Fold: 0\n",
      "Epoch 2/299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7883b8a5844c9ba2b455f9fe48cad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Loss: 3.2100 Macro F1: 0.1315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010b2f1adcc2448c83e36ad781dcc129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] Loss: 4.6150 Macro F1: 0.1334\n",
      "--------------------------------------------------\n",
      "Fold: 0\n",
      "Epoch 3/299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0931e12cf7e84bf196df81d46e2a3857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# skf = sklearn.model_selection.StratifiedKFold(n_splits=20, shuffle=False)\n",
    "skf = sklearn.model_selection.StratifiedKFold(n_splits=10, shuffle=False)\n",
    "t = train_csv.artist\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(np.zeros(len(t)), t)):\n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    data_train = train_csv.loc[train_index]\n",
    "    data_validation = train_csv.loc[test_index]\n",
    "\n",
    "    class_counts = data_train['artist'].value_counts(sort=False).to_dict()\n",
    "    num_samples = sum(class_counts.values())\n",
    "    print(f'cls_cnts: {len(class_counts)}\\nnum_samples:{num_samples}')\n",
    "    labels = data_train['artist'].to_list()\n",
    "\n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "    \n",
    "    # weighted vote를 시도해보기 위해 만들었지만 최종 제출에는 사용하지 않았음\n",
    "    class_weights_keys = le.inverse_transform(list(class_weights.keys()))\n",
    "    class_weights_values = class_weights.values()\n",
    "    class_weights2 = dict(zip(class_weights_keys, class_weights_values))\n",
    "    print(class_weights2)\n",
    "\n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[labels[i]] for i in range(int(num_samples))] \n",
    "    sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "\n",
    "    # batch_size=288; GPU 개당 batch 32개 * 9 == 288\n",
    "    train_dataset = ARTDataset('train', '../Data/data/', data_train, transform=transform_train)\n",
    "    validation_dataset = ARTDataset('validation', '../Data/data/', data_validation, transform=transform_train)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=4,\n",
    "        sampler=sampler,  # trainset에 sampler를 설정해줌\n",
    "        shuffle=False,\n",
    "        num_workers=6,\n",
    "        pin_memory=True\n",
    "        )\n",
    "    validation_loader = DataLoader(\n",
    "        validation_dataset, \n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=6)\n",
    "\n",
    "    ss = pd.read_csv('../Data/data/test.csv')\n",
    "    test_dataset = ARTDataset('test', '../Data/data/', ss, transform=transform_test)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=4,\n",
    "        shuffle=False, \n",
    "        num_workers=6,\n",
    "        pin_memory=True)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': train_loader,\n",
    "        'val': validation_loader,\n",
    "        'test': test_loader\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        'train': len(train_dataset),\n",
    "        'val': len(validation_dataset),\n",
    "        'test': len(test_dataset)\n",
    "    }\n",
    "\n",
    "    # timm에서 모델을 가져옴\n",
    "    device =  torch.device(\"cuda\")\n",
    "    model = timm.create_model('tf_efficientnet_b7_ns', pretrained=True, num_classes=50)\n",
    "    model.to(device)\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "\n",
    "    epochs = 300  # 보통 30~40 epoch에서 멈춥니다.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    # optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    os.makedirs(f'./runs/{run_id}', exist_ok=True)\n",
    "    os.makedirs(f'./cms/', exist_ok=True)\n",
    "    \n",
    "    since = time.time()\n",
    "    best_f1 = 0.0\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    os.environ['WANDB_START_METHOD'] = 'thread'\n",
    "    fold_run_id = f'{run_id}_fold{str(fold)}'\n",
    "    wandb.init(project=\"temp_test\", entity=\"hojunking\", name=fold_run_id)\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    # 학습\n",
    "    for epoch in range(epochs):\n",
    "        print('-'*50)\n",
    "        print(f'Fold: {fold}')\n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            cm_preds = []\n",
    "            cm_labels = []\n",
    "            model_preds = []\n",
    "            model_labels = []\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            for x, y in tqdm(iter(dataloaders[phase])):\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with torch.cuda.amp.autocast(enabled=True):\n",
    "                        y_hat = model(x)\n",
    "                        loss = criterion(y_hat, y)\n",
    "                    _, preds = torch.max(y_hat, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                running_loss += loss.item() * x.size(0)\n",
    "                \n",
    "                model_labels += y.detach().cpu().numpy().tolist()\n",
    "                model_preds += preds.detach().cpu().numpy().tolist()\n",
    "\n",
    "            if phase == 'train' and scheduler != None:\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_f1 = f1_score(\n",
    "                        model_labels, \n",
    "                        model_preds, \n",
    "                        average='macro')\n",
    "            print(f'[{phase}] Loss: {epoch_loss:.4f} Macro F1: {epoch_f1:.4f}')\n",
    "\n",
    "            # 체크포인트 저장\n",
    "            if phase == 'val':\n",
    "                if epoch_f1 > best_f1:\n",
    "                    best_f1 = epoch_f1\n",
    "                    torch.save(model, f'./runs/{run_id}/best_model_fold{fold}.pt')\n",
    "                    confusion_mtx = confusion_matrix(model_labels, model_preds)\n",
    "                    plot_confusion_matrix(confusion_mtx, classes=class_counts.keys(), runid=fold_run_id, epoch=epoch, f1=best_f1)\n",
    "                else:\n",
    "                    # torch.save(model, f'./runs/{run_id}/{epoch}-val_loss{epoch_loss}-val_f1{epoch_f1}.pt')\n",
    "                    pass\n",
    "            \n",
    "            # 로그\n",
    "            if phase == 'val':\n",
    "                wandb.log({\"val_loss\": epoch_loss, \"val_f1\": epoch_f1, \"train_loss\": train_loss, \"train_f1\": train_f1})\n",
    "            else:\n",
    "                train_loss = epoch_loss\n",
    "                train_f1 = epoch_f1\n",
    "            \n",
    "        # EARLY STOPPING\n",
    "        stop = early_stopping(epoch_f1)\n",
    "        if stop:\n",
    "            print(\"called\")   \n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val_F1: {:4f}'.format(best_f1))\n",
    "\n",
    "    # 해당 fold의 checkpoint를 불러와 test\n",
    "    device =  torch.device(\"cuda\")\n",
    "    checkpoint = f'./runs/{run_id}/best_model_fold{fold}.pt'\n",
    "    print(f'CHECKPOINT LOADED: {checkpoint}')\n",
    "    model = torch.load(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(iter(dataloaders['test'])):\n",
    "                batch_pred = model(x)\n",
    "                _, pred = torch.max(batch_pred, 1)\n",
    "                pred = pred.detach().cpu().numpy().tolist()\n",
    "                test_preds.extend(pred)\n",
    "\n",
    "    # trainset에 fit_trainsform 되어있는 LabelEncoder로 inverse transform 해줌\n",
    "    test_preds = le.inverse_transform(test_preds)\n",
    "\n",
    "    sample_submission = pd.read_csv('../Data/data/sample_submission.csv')\n",
    "    sample_submission['artist'] = test_preds\n",
    "    os.makedirs('./output/', exist_ok=True)\n",
    "    sample_submission.to_csv(f'./output/{run_id}_fold{fold}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0-lDq3dFJle"
   },
   "source": [
    "### 투표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qt82afQFJlf"
   },
   "source": [
    "- 경로를 수정해서 사용하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-hk1BrUFJlf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# 경로 수정(run_id*.csv)\n",
    "csvs = glob('./output/20221010220426*.csv')\n",
    "csvs2 = glob('./output/20221030183609*.csv')\n",
    "csvs.extend(csvs2)\n",
    "print(len(csvs))\n",
    "\n",
    "preds = []\n",
    "for csv in csvs:\n",
    "    f = pd.read_csv(csv)\n",
    "    artist = f['artist'].tolist()\n",
    "    preds.append(artist)\n",
    "\n",
    "out = []\n",
    "cols = list(zip(*preds))\n",
    "for c in cols:\n",
    "    most = Counter(c).most_common()[0][0]\n",
    "    out.append(most)\n",
    "\n",
    "print(out[:20])\n",
    "ss = pd.read_csv('../Data/data/sample_submission.csv')\n",
    "ss['artist'] = out\n",
    "ss.to_csv('vote1234.csv', index=False)  # 구분 가능하게 경로 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftjuzKp3FJlf"
   },
   "source": [
    "### 기타\n",
    "- Class Imbalance가 심하기 때문에 Private에서 점수가 크게 흔들릴 가능성이 있다고 판단(실제로도 크게 흔들렸음)\n",
    "- 가장 많은 표를 받은 class가 2개 이상일 경우 weight가 높은 class를 선택하도록 함\n",
    "- Public에서 0.001점 정도 감소\n",
    "- 하지만 Private 점수의 변동을 줄여준다는 보장이 없기 때문에 최종 제출로 선택하지는 않았음\n",
    "- 낮은 weight를 선택하는 것 보다는 높은 weight를 선택했을 때 Public 점수가 0.002점 정도 높았음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVEghVGbFJlf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# class_weights2 = {'Jackson Pollock': 280.75, 'Peter Paul Rubens': 61.03, 'Andrei Rublev': 80.21, 'Eugene Delacroix': 224.6, 'Rene Magritte': 43.19, 'Claude Monet': 100.27, 'Edouard Manet': 95.17, 'Edvard Munch': 133.69, 'Rembrandt': 32.65, 'Marc Chagall': 34.03, 'El Greco': 90.56, 'Leonardo da Vinci': 58.49, 'Albrecht Du rer': 26.87, 'Edgar Degas': 12.08, 'Pieter Bruegel': 69.32, 'Diego Velazquez': 73.88, 'Pablo Picasso': 19.56, 'Andy Warhol': 44.56, 'Titian': 34.03, 'Jan van Eyck': 93.58, 'Paul Klee': 41.59, 'Vincent van Gogh': 9.39, 'Henri Rousseau': 114.59, 'Alfred Sisley': 35.76, 'Mikhail Vrubel': 50.13, 'Pierre-Auguste Renoir': 25.41, 'Amedeo Modigliani': 44.56, 'Vasiliy Kandinskiy': 98.51, 'Kazimir Malevich': 65.29, 'Paul Gauguin': 26.87, 'Georges Seurat': 193.62, 'Gustav Klimt': 86.38, 'Hieronymus Bosch': 51.51, 'Giotto di Bondone': 81.38, 'Michelangelo': 170.15, 'Raphael': 81.38, 'Frida Kahlo': 70.19, 'Francisco Goya': 28.94, 'Sandro Botticelli': 49.25, 'Salvador Dali': 59.73, 'Paul Cezanne': 181.13, 'Diego Rivera': 119.47, 'Gustave Courbet': 140.38, 'Camille Pissarro': 92.05, 'Joan Miro': 77.99, 'Henri Matisse': 48.83, 'Caravaggio': 187.17, 'William Turner': 136.95, 'Piet Mondrian': 100.27, 'Henri de Toulouse-Lautrec': 96.81}\n",
    "\n",
    "csvs = glob('./output/20221010220426*.csv')\n",
    "csvs2 = glob('./output/20221030183609*.csv')\n",
    "csvs.extend(csvs2)\n",
    "print(len(csvs))\n",
    "\n",
    "preds = []\n",
    "called = 0\n",
    "\n",
    "for csv in csvs:\n",
    "    f = pd.read_csv(csv)\n",
    "    artist = f['artist'].tolist()\n",
    "    preds.append(artist)\n",
    "\n",
    "out = []\n",
    "cols = list(zip(*preds))\n",
    "\n",
    "for c in cols:\n",
    "    counted = dict(Counter(c).most_common())\n",
    "    most_cnt = list(counted.values()).count(list(counted.values())[0])\n",
    "\n",
    "    if most_cnt != 1:\n",
    "        called += 1\n",
    "        vote_keys = list(counted.keys())[:most_cnt]\n",
    "        vote_weights = [class_weights2[k] for k in vote_keys]\n",
    "        idx = vote_weights.index(max(vote_weights))\n",
    "        most = vote_keys[idx]\n",
    "\n",
    "        print(f'weighted vote called\\n{vote_keys}: {vote_weights}')\n",
    "        print(f'selected: {most}\\n')\n",
    "    else:\n",
    "        most = Counter(c).most_common()[0][0]\n",
    "    \n",
    "    out.append(most)\n",
    "\n",
    "print(f'called: {called} times')\n",
    "print(out[:20])\n",
    "\n",
    "ss = pd.read_csv('../Data/data/sample_submission.csv')\n",
    "ss['artist'] = out\n",
    "ss.to_csv('max_weightd_vote_20221030183609+20221010220426.csv', index=False)  # 경로 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNYbTcNfFJlg"
   },
   "source": [
    "선택되지 못한 모델들\n",
    "- Noisy Student B6 (10fold): 0.8783410572\n",
    "- convnext_xlarge_384_in22ft1k (10fold): 0.8589929047\n",
    "- EfficientNetV2 XL (10fold): 0.8424065127\n",
    "- CaiT: 수렴이 너무 느려 포기"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e50b4886d2ea2bb1a265ce358850b4c4a237b5572b836d8835f3ebcf42cb944c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
