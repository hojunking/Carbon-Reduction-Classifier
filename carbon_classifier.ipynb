{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6921b1fa-dd0e-4b7e-9fcc-cc0b58e43a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc299d01-d4e2-4ca5-ac38-f947d1b75ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"랜덤 수의 Seed 고정, 재현성 보장\"\"\"\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d41c3842-a9ab-432b-8764-e3154a37ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 업로드 파일이 이미지 포멧이 아닐 경우 Exception 처리 필요 \"\"\"\n",
    "def get_img(path, sub_path=None):\n",
    "    try:\n",
    "        im_bgr = cv2.imread(path)\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "    except: ## 이미지 에러 발생 시 백지로 대체\n",
    "        im_bgr = cv2.imread('')\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f92d90-9501-447a-a564-7c6087c9cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" 데이터 로드 전 전처리 \"\"\"\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(\n",
    "#         self, df, data_root, transform=transform_test):\n",
    "        \n",
    "#         super().__init__()\n",
    "#         self.df = df.reset_index(drop=True).copy()\n",
    "#         self.transform = transform\n",
    "#         self.data_root = data_root\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.df.shape[0]\n",
    "    \n",
    "#     def __getitem__(self, index: int):\n",
    "          \n",
    "#         path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "#         img  = get_img(path)\n",
    "        \n",
    "#         if self.transform:\n",
    "#             img = self.transform(image=img)['image']\n",
    "            \n",
    "#         return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ed4cb45-3665-4083-8e4a-627b6a72806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pre-trained 모델 호출 및 선언\"\"\"\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_arch_str, num_classes= 2,pretrained=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.backbone = models.mobilenet_v3_large(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.classifier[-1] = nn.Linear(self.backbone.classifier[-1].in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c914c00b-276e-4958-b1d5-a5032b401ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inference(images):\n",
    "    # Move the images to the specified device (GPU or CPU)\n",
    "    images = images.to(device)\n",
    "\n",
    "    # Disable gradient calculation and enable inference mode\n",
    "    with torch.no_grad():\n",
    "        # Perform the forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "    # Apply softmax to obtain class probabilities\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "\n",
    "    # Return the predicted class probabilities\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa186779-10d8-4fa6-91e4-d2d066e2e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((260, 260)),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8ee933d-df71-48c2-a91c-fdd4f2c74909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# RUN INFERENCE\n",
    "from PIL import Image\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    architecture = 'mobilenet_v3_large'\n",
    "    model = Model(architecture, 16, pretrained=True)\n",
    "    seed_everything(42)\n",
    "    model_path = './models/mobilenet_v3_large.pth'\n",
    "    \n",
    "    #model = mobilenet_v3_large()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    input_image = './tst_img/toothcup.jpg' # Load your input images here\n",
    "    #input_image = transform(get_img(input_image)) # Apply the transformation\n",
    "    \n",
    "    input_image = Image.open(input_image).convert('RGB')\n",
    "    input_tensor = transform(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    #input_batch = input_batch.to(device)\n",
    "    \n",
    "    # Run inference\n",
    "    output_probabilities = inference(input_batch)\n",
    "    predicted_class_index = torch.argmax(output_probabilities, dim=1)\n",
    "    print(predicted_class_index)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb92a9fd-6e8f-4e62-9bb5-932bb7688a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box\n"
     ]
    }
   ],
   "source": [
    "class_labels  = ['10Kwalk', 'battery', 'box', 'else', 'bottle', 'handkerchief',\n",
    " 'milk', 'paper', 'pet', 'plug', 'receipt', 'shopping bag', 'stairs',\n",
    " 'transportation', 'trash picking', 'dishes']\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit_transform(label_list)\n",
    "# result = le.inverse_transform('0')\n",
    "\n",
    "predicted_class = class_labels[predicted_class_index.item()]\n",
    "print(predicted_class) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560b185-f93f-444f-a7d7-d54820ce6266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
