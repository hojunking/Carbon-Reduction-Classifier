{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6921b1fa-dd0e-4b7e-9fcc-cc0b58e43a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49ed204-4ff5-4192-afd2-3ad2c46508fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc299d01-d4e2-4ca5-ac38-f947d1b75ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"랜덤 수의 Seed 고정, 재현성 보장\"\"\"\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed4cb45-3665-4083-8e4a-627b6a72806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pre-trained 모델 호출 및 선언\"\"\"\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_arch_str, num_classes= 2,pretrained=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.backbone = models.mobilenet_v3_large(pretrained=pretrained) ## 모델 선언 여기 models.##(pretrained =pretrained)\n",
    "        self.backbone.classifier[-1] = nn.Linear(self.backbone.classifier[-1].in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c914c00b-276e-4958-b1d5-a5032b401ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 추론  \"\"\"\n",
    "def inference(images):\n",
    "    \"\"\" Move the images to the specified device (GPU or CPU) \"\"\"\n",
    "    images = images.to(device)\n",
    "\n",
    "    \"\"\" Disable gradient calculation and enable inference mode \"\"\"\n",
    "    with torch.no_grad():\n",
    "        \"\"\" Perform the forward pass \"\"\"\n",
    "        outputs = model(images)\n",
    "    \"\"\" Apply softmax to obtain class probabilities \"\"\"\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0867b946-3216-4b77-b3e9-7d1a291896a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 1, 2차 모델 선언 \"\"\"\n",
    "def model_define(category):\n",
    "    \"\"\" 1차 분류 ('10Kwalk', 'battery', 'box', 'else', 'bottle', 'handkerchief',\n",
    " 'milk', 'paper', 'pet', 'plug', 'receipt', 'shopping bag', 'stairs',\n",
    " 'transportation', 'trash picking', 'dishes' \"\"\"\n",
    "    class_num = 16\n",
    "    model_path = 'mobilenet_v3_16classes.pth'\n",
    "    \n",
    "    \n",
    "    if category == 'bottle':\n",
    "        \"\"\" bottle (양치컵 사용하기, 텀블러 사용하기) \"\"\"  \n",
    "        class_num = 2\n",
    "        model_path = 'mobilenet_v3_bottle.pth'\n",
    "    \n",
    "    elif category == 'dishes':\n",
    "        \"\"\" dishes (랩 쓰지 않기, 잔반 남기지 않기, 채소식단) \"\"\"\n",
    "        class_num = 3\n",
    "        model_path = 'mobilenet_v3_dishes.pth'\n",
    "\n",
    "    elif category == 'box':\n",
    "        \"\"\" 테이브 제거 검증 \"\"\"\n",
    "        class_num = 2\n",
    "        model_path = 'mobilenet_v3_box.pth'\n",
    "    \n",
    "    elif category == 'pet':\n",
    "        \"\"\" 페트병 라벨 제거 검증 \"\"\"\n",
    "        class_num = 2  \n",
    "        ]\n",
    "        \n",
    "        \n",
    "        model_path = 'mobilenet_v3_pet.pth'\n",
    "    model = Model('mobilenet_v3_large', class_num, pretrained=True)\n",
    "    model.load_state_dict(torch.load('./models/' + model_path))\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa186779-10d8-4fa6-91e4-d2d066e2e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 이미지 분석을 위한 기본 전처리 \"\"\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((260, 260)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a231fae-18eb-42ac-937b-942a9ed60a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(image_path):\n",
    "    input_image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(input_image)\n",
    "    return input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7163dbcb-41e8-4532-8b1c-826b2d88b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_category(category, result):\n",
    "    \n",
    "    if category == 'bottle':\n",
    "        class_labels = [\"toothcup\",\"tumbler\"]\n",
    "    elif category == 'pet':\n",
    "        class_labels = [\"unlabeled\",\"labeled\"]\n",
    "    elif category == 'box':\n",
    "        class_labels = [\"box\",\"untapedBox\"]\n",
    "    elif category =='dishes':\n",
    "        class_labels = ['wrap','leftover','green dish']\n",
    "    else:\n",
    "        print('here')\n",
    "        class_labels  = ['10Kwalk', 'battery', 'box', 'else', 'bottle', 'handkerchief',\n",
    "     'milk', 'paper', 'pet', 'plug', 'receipt', 'shopping bag', 'stairs',\n",
    "     'transportation', 'trash picking', 'dishes']\n",
    "        \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit_transform(class_labels)\n",
    "    \n",
    "    return le.inverse_transform([result])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8ee933d-df71-48c2-a91c-fdd4f2c74909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "here\n",
      "fist classification: ['bottle']\n",
      "['bottle']\n",
      "second classification: ['toothcup']\n"
     ]
    }
   ],
   "source": [
    "# RUN INFERENCE\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Description of your script')\n",
    "    parser.add_argument('--option1', type=str)\n",
    "    args = parser.parse_args()\n",
    "    image_path = args.option1\n",
    "    \n",
    "    \n",
    "    seed_everything(42)\n",
    "    category = ''\n",
    "    #image_path = './tst_img/toothcup.jpg' # Load your input images here\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model_define(category)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    input_batch = load_img(image_path)\n",
    "    input_batch = input_batch.to(device)\n",
    "    \n",
    "    # Run inference\n",
    "    output_probabilities = inference(input_batch)\n",
    "    predicted_class_index = torch.argmax(output_probabilities, dim=1)\n",
    "    result = predicted_class_index.item()\n",
    "    result = decode_category(category, result)\n",
    "    \n",
    "    print(f'first classification: {result}')\n",
    "    category = result\n",
    "    if category in ['bottle' , 'pet', 'box', 'dishes']:\n",
    "        model = model_define(category)\n",
    "        model = model.to(device)\n",
    "        output_probabilities = inference(input_batch)\n",
    "        predicted_class_index = torch.argmax(output_probabilities, dim=1)\n",
    "        result = predicted_class_index.item()\n",
    "        result = decode_category(category, result)\n",
    "        print(f'final classification: {result}')\n",
    "        \n",
    "    #print(f'result : {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fb92a9fd-6e8f-4e62-9bb5-932bb7688a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bottle']\n"
     ]
    }
   ],
   "source": [
    "class_labels  = ['10Kwalk', 'battery', 'box', 'else', 'bottle', 'handkerchief',\n",
    " 'milk', 'paper', 'pet', 'plug', 'receipt', 'shopping bag', 'stairs',\n",
    " 'transportation', 'trash picking', 'dishes']\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit_transform(class_labels)\n",
    "result = le.inverse_transform([])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0350b-2d6a-4004-84d1-52eb0d7b3762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
